{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn_Modelling\n",
    "#### Reference: https://www.kaggle.com/aakash50897/churn-modellingcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "5       8  113755.78              2          1               0   \n",
       "6       7       0.00              2          1               1   \n",
       "7       4  115046.74              4          1               0   \n",
       "8       4  142051.07              2          0               1   \n",
       "9       2  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "dataset[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hong\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Hong\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:] # Avoiding dummy variable trap!\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def build_classifier():\n",
    "    # Initializing the ANN\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer with dropout\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    # classifier.add(Dropout(rate = 0.2))\n",
    "\n",
    "    # Adding the second hidden layer with dropout\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    # classifier.add(Dropout(rate = 0.2))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 6)                 72        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = build_classifier()\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/300\n",
      "8000/8000 [==============================] - 1s 119us/step - loss: 0.5327 - acc: 0.7958 - val_loss: 0.4367 - val_acc: 0.7975\n",
      "Epoch 2/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.4329 - acc: 0.7960 - val_loss: 0.4292 - val_acc: 0.7975\n",
      "Epoch 3/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.4287 - acc: 0.7960 - val_loss: 0.4255 - val_acc: 0.7975\n",
      "Epoch 4/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.4262 - acc: 0.7960 - val_loss: 0.4227 - val_acc: 0.7975\n",
      "Epoch 5/300\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4245 - acc: 0.809 - 0s 49us/step - loss: 0.4232 - acc: 0.8109 - val_loss: 0.4184 - val_acc: 0.8250\n",
      "Epoch 6/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.4189 - acc: 0.8250 - val_loss: 0.4127 - val_acc: 0.8325\n",
      "Epoch 7/300\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.4148 - acc: 0.8279 - val_loss: 0.4120 - val_acc: 0.8355\n",
      "Epoch 8/300\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.4114 - acc: 0.8321 - val_loss: 0.4063 - val_acc: 0.8405\n",
      "Epoch 9/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.4085 - acc: 0.8334 - val_loss: 0.4034 - val_acc: 0.8400\n",
      "Epoch 10/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.4061 - acc: 0.8356 - val_loss: 0.4010 - val_acc: 0.8455\n",
      "Epoch 11/300\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4044 - acc: 0.8351 - val_loss: 0.4001 - val_acc: 0.8415\n",
      "Epoch 12/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.4032 - acc: 0.8350 - val_loss: 0.3997 - val_acc: 0.8450\n",
      "Epoch 13/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.4014 - acc: 0.8355 - val_loss: 0.3975 - val_acc: 0.8420\n",
      "Epoch 14/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.4010 - acc: 0.8351 - val_loss: 0.3954 - val_acc: 0.8430\n",
      "Epoch 15/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3998 - acc: 0.8362 - val_loss: 0.3977 - val_acc: 0.8430\n",
      "Epoch 16/300\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3992 - acc: 0.8357 - val_loss: 0.3947 - val_acc: 0.8440\n",
      "Epoch 17/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3981 - acc: 0.8354 - val_loss: 0.3958 - val_acc: 0.8415\n",
      "Epoch 18/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3977 - acc: 0.8346 - val_loss: 0.3955 - val_acc: 0.8420\n",
      "Epoch 19/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3973 - acc: 0.8342 - val_loss: 0.3957 - val_acc: 0.8425\n",
      "Epoch 20/300\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3971 - acc: 0.8331 - val_loss: 0.3946 - val_acc: 0.8410\n",
      "Epoch 21/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3966 - acc: 0.8357 - val_loss: 0.3940 - val_acc: 0.8420\n",
      "Epoch 22/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3963 - acc: 0.8357 - val_loss: 0.3950 - val_acc: 0.8420\n",
      "Epoch 23/300\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3957 - acc: 0.8351 - val_loss: 0.3944 - val_acc: 0.8430\n",
      "Epoch 24/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3953 - acc: 0.8339 - val_loss: 0.3929 - val_acc: 0.8435\n",
      "Epoch 25/300\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3951 - acc: 0.8362 - val_loss: 0.3946 - val_acc: 0.8420\n",
      "Epoch 26/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3948 - acc: 0.8344 - val_loss: 0.3937 - val_acc: 0.8430\n",
      "Epoch 27/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3948 - acc: 0.8346 - val_loss: 0.3942 - val_acc: 0.8410\n",
      "Epoch 28/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3940 - acc: 0.8356 - val_loss: 0.3932 - val_acc: 0.8445\n",
      "Epoch 29/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3943 - acc: 0.8339 - val_loss: 0.3935 - val_acc: 0.8415\n",
      "Epoch 30/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3942 - acc: 0.8346 - val_loss: 0.3962 - val_acc: 0.8440\n",
      "Epoch 31/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3938 - acc: 0.8355 - val_loss: 0.3925 - val_acc: 0.8415\n",
      "Epoch 32/300\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3939 - acc: 0.8349 - val_loss: 0.3953 - val_acc: 0.8435\n",
      "Epoch 33/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3937 - acc: 0.8359 - val_loss: 0.3959 - val_acc: 0.8420\n",
      "Epoch 34/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3937 - acc: 0.8360 - val_loss: 0.3929 - val_acc: 0.8440\n",
      "Epoch 35/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3943 - acc: 0.8354 - val_loss: 0.3926 - val_acc: 0.8400\n",
      "Epoch 36/300\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.3938 - acc: 0.8361 - val_loss: 0.3929 - val_acc: 0.8420\n",
      "Epoch 37/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3936 - acc: 0.8370 - val_loss: 0.3948 - val_acc: 0.8440\n",
      "Epoch 38/300\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3934 - acc: 0.8354 - val_loss: 0.3932 - val_acc: 0.8410\n",
      "Epoch 39/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3933 - acc: 0.8359 - val_loss: 0.3957 - val_acc: 0.8430\n",
      "Epoch 40/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3931 - acc: 0.8376 - val_loss: 0.3940 - val_acc: 0.8415\n",
      "Epoch 41/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3934 - acc: 0.8359 - val_loss: 0.3955 - val_acc: 0.8395\n",
      "Epoch 42/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3936 - acc: 0.8356 - val_loss: 0.3928 - val_acc: 0.8420\n",
      "Epoch 43/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3933 - acc: 0.8361 - val_loss: 0.3968 - val_acc: 0.8445\n",
      "Epoch 44/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3931 - acc: 0.8376 - val_loss: 0.3921 - val_acc: 0.8415\n",
      "Epoch 45/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3936 - acc: 0.8365 - val_loss: 0.3929 - val_acc: 0.8415\n",
      "Epoch 46/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3931 - acc: 0.8374 - val_loss: 0.3939 - val_acc: 0.8435\n",
      "Epoch 47/300\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3931 - acc: 0.8365 - val_loss: 0.3959 - val_acc: 0.8435\n",
      "Epoch 48/300\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3934 - acc: 0.8377 - val_loss: 0.3929 - val_acc: 0.8420\n",
      "Epoch 49/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3933 - acc: 0.8375 - val_loss: 0.3946 - val_acc: 0.8430\n",
      "Epoch 50/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3931 - acc: 0.8369 - val_loss: 0.3923 - val_acc: 0.8435\n",
      "Epoch 51/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3932 - acc: 0.8354 - val_loss: 0.3921 - val_acc: 0.8420\n",
      "Epoch 52/300\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3930 - acc: 0.8360 - val_loss: 0.3918 - val_acc: 0.8440\n",
      "Epoch 53/300\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3931 - acc: 0.8356 - val_loss: 0.3918 - val_acc: 0.8425\n",
      "Epoch 54/300\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.3932 - acc: 0.8356 - val_loss: 0.3913 - val_acc: 0.8430\n",
      "Epoch 55/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3933 - acc: 0.8372 - val_loss: 0.3923 - val_acc: 0.8435\n",
      "Epoch 56/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3930 - acc: 0.8369 - val_loss: 0.3917 - val_acc: 0.8420\n",
      "Epoch 57/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3931 - acc: 0.8367 - val_loss: 0.3932 - val_acc: 0.8420\n",
      "Epoch 58/300\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.3930 - acc: 0.8362 - val_loss: 0.3936 - val_acc: 0.8450\n",
      "Epoch 59/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3927 - acc: 0.8370 - val_loss: 0.3915 - val_acc: 0.8420\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3926 - acc: 0.8364 - val_loss: 0.3914 - val_acc: 0.8425\n",
      "Epoch 61/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3928 - acc: 0.8366 - val_loss: 0.3944 - val_acc: 0.8425\n",
      "Epoch 62/300\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3930 - acc: 0.8390 - val_loss: 0.3919 - val_acc: 0.8415\n",
      "Epoch 63/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3928 - acc: 0.8385 - val_loss: 0.3917 - val_acc: 0.8445\n",
      "Epoch 64/300\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.3930 - acc: 0.8372 - val_loss: 0.3923 - val_acc: 0.8425\n",
      "Epoch 65/300\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.3926 - acc: 0.8385 - val_loss: 0.3930 - val_acc: 0.8440\n",
      "Epoch 66/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3927 - acc: 0.8377 - val_loss: 0.3932 - val_acc: 0.8395\n",
      "Epoch 67/300\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.3926 - acc: 0.8371 - val_loss: 0.3915 - val_acc: 0.8440\n",
      "Epoch 68/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3923 - acc: 0.8384 - val_loss: 0.3951 - val_acc: 0.8405\n",
      "Epoch 69/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3927 - acc: 0.8385 - val_loss: 0.3935 - val_acc: 0.8430\n",
      "Epoch 70/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3924 - acc: 0.8375 - val_loss: 0.3911 - val_acc: 0.8430\n",
      "Epoch 71/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3918 - acc: 0.8384 - val_loss: 0.3932 - val_acc: 0.8420\n",
      "Epoch 72/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3921 - acc: 0.8380 - val_loss: 0.3913 - val_acc: 0.8440\n",
      "Epoch 73/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3914 - acc: 0.8389 - val_loss: 0.3925 - val_acc: 0.8435\n",
      "Epoch 74/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3915 - acc: 0.8392 - val_loss: 0.3903 - val_acc: 0.8415\n",
      "Epoch 75/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3907 - acc: 0.8399 - val_loss: 0.3935 - val_acc: 0.8415\n",
      "Epoch 76/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3902 - acc: 0.8394 - val_loss: 0.3926 - val_acc: 0.8410\n",
      "Epoch 77/300\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3896 - acc: 0.8401 - val_loss: 0.3899 - val_acc: 0.8435\n",
      "Epoch 78/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3887 - acc: 0.8412 - val_loss: 0.3895 - val_acc: 0.8400\n",
      "Epoch 79/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3879 - acc: 0.8405 - val_loss: 0.3884 - val_acc: 0.8405\n",
      "Epoch 80/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3872 - acc: 0.8405 - val_loss: 0.3852 - val_acc: 0.8400\n",
      "Epoch 81/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3855 - acc: 0.8397 - val_loss: 0.3857 - val_acc: 0.8385\n",
      "Epoch 82/300\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3831 - acc: 0.8400 - val_loss: 0.3808 - val_acc: 0.8425\n",
      "Epoch 83/300\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.3807 - acc: 0.8415 - val_loss: 0.3808 - val_acc: 0.8390\n",
      "Epoch 84/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3789 - acc: 0.8392 - val_loss: 0.3800 - val_acc: 0.8375\n",
      "Epoch 85/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3767 - acc: 0.8401 - val_loss: 0.3757 - val_acc: 0.8360\n",
      "Epoch 86/300\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3745 - acc: 0.8425 - val_loss: 0.3712 - val_acc: 0.8400\n",
      "Epoch 87/300\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.3726 - acc: 0.8414 - val_loss: 0.3685 - val_acc: 0.8375\n",
      "Epoch 88/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3711 - acc: 0.8415 - val_loss: 0.3657 - val_acc: 0.8410\n",
      "Epoch 89/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3687 - acc: 0.8412 - val_loss: 0.3617 - val_acc: 0.8465\n",
      "Epoch 90/300\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3663 - acc: 0.8444 - val_loss: 0.3583 - val_acc: 0.8500\n",
      "Epoch 91/300\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3628 - acc: 0.8469 - val_loss: 0.3610 - val_acc: 0.8490\n",
      "Epoch 92/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3604 - acc: 0.8500 - val_loss: 0.3519 - val_acc: 0.8525\n",
      "Epoch 93/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3575 - acc: 0.8506 - val_loss: 0.3491 - val_acc: 0.8575\n",
      "Epoch 94/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3565 - acc: 0.8535 - val_loss: 0.3482 - val_acc: 0.8570\n",
      "Epoch 95/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3557 - acc: 0.8561 - val_loss: 0.3461 - val_acc: 0.8585\n",
      "Epoch 96/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3543 - acc: 0.8557 - val_loss: 0.3469 - val_acc: 0.8590\n",
      "Epoch 97/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3533 - acc: 0.8586 - val_loss: 0.3442 - val_acc: 0.8625\n",
      "Epoch 98/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3532 - acc: 0.8586 - val_loss: 0.3445 - val_acc: 0.8610\n",
      "Epoch 99/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3527 - acc: 0.8584 - val_loss: 0.3435 - val_acc: 0.8610\n",
      "Epoch 100/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3518 - acc: 0.8592 - val_loss: 0.3441 - val_acc: 0.8615\n",
      "Epoch 101/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3519 - acc: 0.8611 - val_loss: 0.3435 - val_acc: 0.8600\n",
      "Epoch 102/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3508 - acc: 0.8586 - val_loss: 0.3399 - val_acc: 0.8625\n",
      "Epoch 103/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3512 - acc: 0.8600 - val_loss: 0.3405 - val_acc: 0.8620\n",
      "Epoch 104/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3499 - acc: 0.8605 - val_loss: 0.3421 - val_acc: 0.8585\n",
      "Epoch 105/300\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3501 - acc: 0.8599 - val_loss: 0.3400 - val_acc: 0.8640\n",
      "Epoch 106/300\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3496 - acc: 0.8606 - val_loss: 0.3386 - val_acc: 0.8670\n",
      "Epoch 107/300\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3486 - acc: 0.8607 - val_loss: 0.3390 - val_acc: 0.8665\n",
      "Epoch 108/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3490 - acc: 0.8625 - val_loss: 0.3452 - val_acc: 0.8590\n",
      "Epoch 109/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3488 - acc: 0.8604 - val_loss: 0.3365 - val_acc: 0.8640\n",
      "Epoch 110/300\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3490 - acc: 0.8624 - val_loss: 0.3396 - val_acc: 0.8620\n",
      "Epoch 111/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3485 - acc: 0.8620 - val_loss: 0.3378 - val_acc: 0.8625\n",
      "Epoch 112/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3478 - acc: 0.8621 - val_loss: 0.3414 - val_acc: 0.8615\n",
      "Epoch 113/300\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3481 - acc: 0.8607 - val_loss: 0.3368 - val_acc: 0.8655\n",
      "Epoch 114/300\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3480 - acc: 0.8596 - val_loss: 0.3374 - val_acc: 0.8650\n",
      "Epoch 115/300\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.3473 - acc: 0.8612 - val_loss: 0.3447 - val_acc: 0.8595\n",
      "Epoch 116/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3479 - acc: 0.8615 - val_loss: 0.3383 - val_acc: 0.8600\n",
      "Epoch 117/300\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3469 - acc: 0.8626 - val_loss: 0.3360 - val_acc: 0.8650\n",
      "Epoch 118/300\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.3466 - acc: 0.8609 - val_loss: 0.3366 - val_acc: 0.8700\n",
      "Epoch 119/300\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.3472 - acc: 0.8597 - val_loss: 0.3358 - val_acc: 0.8660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3456 - acc: 0.8607 - val_loss: 0.3402 - val_acc: 0.8655\n",
      "Epoch 121/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3467 - acc: 0.8609 - val_loss: 0.3402 - val_acc: 0.8595\n",
      "Epoch 122/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3465 - acc: 0.8611 - val_loss: 0.3403 - val_acc: 0.8625\n",
      "Epoch 123/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3470 - acc: 0.8619 - val_loss: 0.3375 - val_acc: 0.8655\n",
      "Epoch 124/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3461 - acc: 0.8612 - val_loss: 0.3364 - val_acc: 0.8630\n",
      "Epoch 125/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3460 - acc: 0.8599 - val_loss: 0.3392 - val_acc: 0.8610\n",
      "Epoch 126/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3452 - acc: 0.8616 - val_loss: 0.3364 - val_acc: 0.8640\n",
      "Epoch 127/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3457 - acc: 0.8611 - val_loss: 0.3338 - val_acc: 0.8655\n",
      "Epoch 128/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3461 - acc: 0.8629 - val_loss: 0.3357 - val_acc: 0.8655\n",
      "Epoch 129/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3455 - acc: 0.8600 - val_loss: 0.3366 - val_acc: 0.8645\n",
      "Epoch 130/300\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3455 - acc: 0.8615 - val_loss: 0.3396 - val_acc: 0.8630\n",
      "Epoch 131/300\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3456 - acc: 0.8591 - val_loss: 0.3360 - val_acc: 0.8660\n",
      "Epoch 132/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3447 - acc: 0.8612 - val_loss: 0.3416 - val_acc: 0.8595\n",
      "Epoch 133/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3444 - acc: 0.8606 - val_loss: 0.3425 - val_acc: 0.8575\n",
      "Epoch 134/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3444 - acc: 0.8627 - val_loss: 0.3327 - val_acc: 0.8670\n",
      "Epoch 135/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3444 - acc: 0.8616 - val_loss: 0.3434 - val_acc: 0.8540\n",
      "Epoch 136/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3442 - acc: 0.8612 - val_loss: 0.3349 - val_acc: 0.8670\n",
      "Epoch 137/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3448 - acc: 0.8604 - val_loss: 0.3320 - val_acc: 0.8650\n",
      "Epoch 138/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3453 - acc: 0.8619 - val_loss: 0.3367 - val_acc: 0.8635\n",
      "Epoch 139/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3445 - acc: 0.8617 - val_loss: 0.3359 - val_acc: 0.8635\n",
      "Epoch 140/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3443 - acc: 0.8625 - val_loss: 0.3458 - val_acc: 0.8560\n",
      "Epoch 141/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3446 - acc: 0.8611 - val_loss: 0.3368 - val_acc: 0.8600\n",
      "Epoch 142/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3448 - acc: 0.8614 - val_loss: 0.3384 - val_acc: 0.8585\n",
      "Epoch 143/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3444 - acc: 0.8614 - val_loss: 0.3333 - val_acc: 0.8615\n",
      "Epoch 144/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3438 - acc: 0.8609 - val_loss: 0.3355 - val_acc: 0.8635\n",
      "Epoch 145/300\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3437 - acc: 0.8612 - val_loss: 0.3322 - val_acc: 0.8635\n",
      "Epoch 146/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3438 - acc: 0.8606 - val_loss: 0.3360 - val_acc: 0.8660\n",
      "Epoch 147/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3441 - acc: 0.8614 - val_loss: 0.3331 - val_acc: 0.8665\n",
      "Epoch 148/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3444 - acc: 0.8607 - val_loss: 0.3342 - val_acc: 0.8645\n",
      "Epoch 149/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3439 - acc: 0.8624 - val_loss: 0.3341 - val_acc: 0.8600\n",
      "Epoch 150/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3440 - acc: 0.8629 - val_loss: 0.3333 - val_acc: 0.8650\n",
      "Epoch 151/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3435 - acc: 0.8614 - val_loss: 0.3372 - val_acc: 0.8600\n",
      "Epoch 152/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3439 - acc: 0.8616 - val_loss: 0.3340 - val_acc: 0.8620\n",
      "Epoch 153/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3437 - acc: 0.8624 - val_loss: 0.3362 - val_acc: 0.8615\n",
      "Epoch 154/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3437 - acc: 0.8629 - val_loss: 0.3334 - val_acc: 0.8650\n",
      "Epoch 155/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3430 - acc: 0.8606 - val_loss: 0.3332 - val_acc: 0.8685\n",
      "Epoch 156/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3433 - acc: 0.8624 - val_loss: 0.3344 - val_acc: 0.8640\n",
      "Epoch 157/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3435 - acc: 0.8605 - val_loss: 0.3420 - val_acc: 0.8565\n",
      "Epoch 158/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3430 - acc: 0.8632 - val_loss: 0.3367 - val_acc: 0.8590\n",
      "Epoch 159/300\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3431 - acc: 0.8611 - val_loss: 0.3365 - val_acc: 0.8600\n",
      "Epoch 160/300\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.3427 - acc: 0.8626 - val_loss: 0.3363 - val_acc: 0.8615\n",
      "Epoch 161/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3425 - acc: 0.8620 - val_loss: 0.3332 - val_acc: 0.8640\n",
      "Epoch 162/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3434 - acc: 0.8615 - val_loss: 0.3323 - val_acc: 0.8645\n",
      "Epoch 163/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3424 - acc: 0.8607 - val_loss: 0.3367 - val_acc: 0.8605\n",
      "Epoch 164/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3425 - acc: 0.8610 - val_loss: 0.3335 - val_acc: 0.8610\n",
      "Epoch 165/300\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3433 - acc: 0.8614 - val_loss: 0.3364 - val_acc: 0.8640\n",
      "Epoch 166/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3421 - acc: 0.8617 - val_loss: 0.3406 - val_acc: 0.8550\n",
      "Epoch 167/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3419 - acc: 0.8626 - val_loss: 0.3329 - val_acc: 0.8665\n",
      "Epoch 168/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3428 - acc: 0.8617 - val_loss: 0.3333 - val_acc: 0.8660\n",
      "Epoch 169/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3420 - acc: 0.8622 - val_loss: 0.3352 - val_acc: 0.8605\n",
      "Epoch 170/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3424 - acc: 0.8624 - val_loss: 0.3333 - val_acc: 0.8615\n",
      "Epoch 171/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3425 - acc: 0.8621 - val_loss: 0.3329 - val_acc: 0.8600\n",
      "Epoch 172/300\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3419 - acc: 0.8642 - val_loss: 0.3340 - val_acc: 0.8590\n",
      "Epoch 173/300\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3414 - acc: 0.8612 - val_loss: 0.3327 - val_acc: 0.8620\n",
      "Epoch 174/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3421 - acc: 0.8604 - val_loss: 0.3373 - val_acc: 0.8605\n",
      "Epoch 175/300\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.3423 - acc: 0.8627 - val_loss: 0.3350 - val_acc: 0.8600\n",
      "Epoch 176/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3418 - acc: 0.8612 - val_loss: 0.3346 - val_acc: 0.8650\n",
      "Epoch 177/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3428 - acc: 0.8602 - val_loss: 0.3368 - val_acc: 0.8595\n",
      "Epoch 178/300\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3421 - acc: 0.8622 - val_loss: 0.3318 - val_acc: 0.8640\n",
      "Epoch 179/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3422 - acc: 0.8610 - val_loss: 0.3320 - val_acc: 0.8635\n",
      "Epoch 180/300\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3420 - acc: 0.8620 - val_loss: 0.3332 - val_acc: 0.8600\n",
      "Epoch 181/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3417 - acc: 0.8625 - val_loss: 0.3361 - val_acc: 0.8595\n",
      "Epoch 182/300\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.3429 - acc: 0.8619 - val_loss: 0.3340 - val_acc: 0.8605\n",
      "Epoch 183/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3421 - acc: 0.8609 - val_loss: 0.3327 - val_acc: 0.8645\n",
      "Epoch 184/300\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3415 - acc: 0.8624 - val_loss: 0.3351 - val_acc: 0.8605\n",
      "Epoch 185/300\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.3412 - acc: 0.8614 - val_loss: 0.3336 - val_acc: 0.8575\n",
      "Epoch 186/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3417 - acc: 0.8614 - val_loss: 0.3342 - val_acc: 0.8645\n",
      "Epoch 187/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3415 - acc: 0.8627 - val_loss: 0.3344 - val_acc: 0.8625\n",
      "Epoch 188/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3413 - acc: 0.8622 - val_loss: 0.3346 - val_acc: 0.8635\n",
      "Epoch 189/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3419 - acc: 0.8616 - val_loss: 0.3332 - val_acc: 0.8650\n",
      "Epoch 190/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3415 - acc: 0.8599 - val_loss: 0.3326 - val_acc: 0.8650\n",
      "Epoch 191/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3415 - acc: 0.8620 - val_loss: 0.3316 - val_acc: 0.8665\n",
      "Epoch 192/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3409 - acc: 0.8624 - val_loss: 0.3346 - val_acc: 0.8635\n",
      "Epoch 193/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3418 - acc: 0.8607 - val_loss: 0.3357 - val_acc: 0.8585\n",
      "Epoch 194/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3411 - acc: 0.8604 - val_loss: 0.3357 - val_acc: 0.8650\n",
      "Epoch 195/300\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.3408 - acc: 0.8617 - val_loss: 0.3339 - val_acc: 0.8620\n",
      "Epoch 196/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3411 - acc: 0.8615 - val_loss: 0.3384 - val_acc: 0.8615\n",
      "Epoch 197/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3422 - acc: 0.8609 - val_loss: 0.3326 - val_acc: 0.8680\n",
      "Epoch 198/300\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3417 - acc: 0.8601 - val_loss: 0.3373 - val_acc: 0.8580\n",
      "Epoch 199/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3413 - acc: 0.8607 - val_loss: 0.3370 - val_acc: 0.8600\n",
      "Epoch 200/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3411 - acc: 0.8607 - val_loss: 0.3333 - val_acc: 0.8640\n",
      "Epoch 201/300\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3408 - acc: 0.8602 - val_loss: 0.3435 - val_acc: 0.8535\n",
      "Epoch 202/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3414 - acc: 0.8619 - val_loss: 0.3330 - val_acc: 0.8685\n",
      "Epoch 203/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3415 - acc: 0.8624 - val_loss: 0.3422 - val_acc: 0.8555\n",
      "Epoch 204/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3411 - acc: 0.8602 - val_loss: 0.3409 - val_acc: 0.8585\n",
      "Epoch 205/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3412 - acc: 0.8617 - val_loss: 0.3367 - val_acc: 0.8575\n",
      "Epoch 206/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3407 - acc: 0.8626 - val_loss: 0.3339 - val_acc: 0.8600\n",
      "Epoch 207/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3405 - acc: 0.8607 - val_loss: 0.3341 - val_acc: 0.8580\n",
      "Epoch 208/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3410 - acc: 0.8612 - val_loss: 0.3321 - val_acc: 0.8625\n",
      "Epoch 209/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3405 - acc: 0.8627 - val_loss: 0.3352 - val_acc: 0.8595\n",
      "Epoch 210/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3404 - acc: 0.8612 - val_loss: 0.3368 - val_acc: 0.8590\n",
      "Epoch 211/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3409 - acc: 0.8609 - val_loss: 0.3325 - val_acc: 0.8630\n",
      "Epoch 212/300\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3406 - acc: 0.8629 - val_loss: 0.3377 - val_acc: 0.8605\n",
      "Epoch 213/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3404 - acc: 0.8605 - val_loss: 0.3336 - val_acc: 0.8600\n",
      "Epoch 214/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3405 - acc: 0.8619 - val_loss: 0.3349 - val_acc: 0.8625\n",
      "Epoch 215/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3403 - acc: 0.8620 - val_loss: 0.3385 - val_acc: 0.8600\n",
      "Epoch 216/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3407 - acc: 0.8624 - val_loss: 0.3346 - val_acc: 0.8670\n",
      "Epoch 217/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3403 - acc: 0.8632 - val_loss: 0.3359 - val_acc: 0.8590\n",
      "Epoch 218/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3403 - acc: 0.8614 - val_loss: 0.3339 - val_acc: 0.8625\n",
      "Epoch 219/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3404 - acc: 0.8614 - val_loss: 0.3333 - val_acc: 0.8600\n",
      "Epoch 220/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3401 - acc: 0.8632 - val_loss: 0.3336 - val_acc: 0.8645\n",
      "Epoch 221/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3402 - acc: 0.8639 - val_loss: 0.3347 - val_acc: 0.8590\n",
      "Epoch 222/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3402 - acc: 0.8626 - val_loss: 0.3347 - val_acc: 0.8630\n",
      "Epoch 223/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3401 - acc: 0.8624 - val_loss: 0.3332 - val_acc: 0.8630\n",
      "Epoch 224/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3394 - acc: 0.8616 - val_loss: 0.3349 - val_acc: 0.8620\n",
      "Epoch 225/300\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3398 - acc: 0.8607 - val_loss: 0.3399 - val_acc: 0.8555\n",
      "Epoch 226/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3391 - acc: 0.8617 - val_loss: 0.3393 - val_acc: 0.8570\n",
      "Epoch 227/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3396 - acc: 0.8610 - val_loss: 0.3356 - val_acc: 0.8600\n",
      "Epoch 228/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3389 - acc: 0.8616 - val_loss: 0.3420 - val_acc: 0.8575\n",
      "Epoch 229/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3402 - acc: 0.8626 - val_loss: 0.3329 - val_acc: 0.8615\n",
      "Epoch 230/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3397 - acc: 0.8626 - val_loss: 0.3342 - val_acc: 0.8645\n",
      "Epoch 231/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3399 - acc: 0.8622 - val_loss: 0.3357 - val_acc: 0.8585\n",
      "Epoch 232/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3390 - acc: 0.8627 - val_loss: 0.3339 - val_acc: 0.8605\n",
      "Epoch 233/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3397 - acc: 0.8629 - val_loss: 0.3360 - val_acc: 0.8600\n",
      "Epoch 234/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3395 - acc: 0.8621 - val_loss: 0.3379 - val_acc: 0.8590\n",
      "Epoch 235/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3387 - acc: 0.8611 - val_loss: 0.3333 - val_acc: 0.8625\n",
      "Epoch 236/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3387 - acc: 0.8630 - val_loss: 0.3368 - val_acc: 0.8605\n",
      "Epoch 237/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3390 - acc: 0.8630 - val_loss: 0.3325 - val_acc: 0.8645\n",
      "Epoch 238/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3398 - acc: 0.8634 - val_loss: 0.3356 - val_acc: 0.8620\n",
      "Epoch 239/300\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3394 - acc: 0.8620 - val_loss: 0.3458 - val_acc: 0.8505\n",
      "Epoch 240/300\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.3394 - acc: 0.8600 - val_loss: 0.3340 - val_acc: 0.8570\n",
      "Epoch 241/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3399 - acc: 0.8625 - val_loss: 0.3360 - val_acc: 0.8590\n",
      "Epoch 242/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3392 - acc: 0.8636 - val_loss: 0.3343 - val_acc: 0.8650\n",
      "Epoch 243/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3394 - acc: 0.8619 - val_loss: 0.3359 - val_acc: 0.8590\n",
      "Epoch 244/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3388 - acc: 0.8609 - val_loss: 0.3341 - val_acc: 0.8645\n",
      "Epoch 245/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3397 - acc: 0.8631 - val_loss: 0.3373 - val_acc: 0.8585\n",
      "Epoch 246/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3390 - acc: 0.8614 - val_loss: 0.3337 - val_acc: 0.8670\n",
      "Epoch 247/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3389 - acc: 0.8624 - val_loss: 0.3337 - val_acc: 0.8655\n",
      "Epoch 248/300\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.3392 - acc: 0.8612 - val_loss: 0.3345 - val_acc: 0.8625\n",
      "Epoch 249/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3391 - acc: 0.8639 - val_loss: 0.3361 - val_acc: 0.8585\n",
      "Epoch 250/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3388 - acc: 0.8605 - val_loss: 0.3328 - val_acc: 0.8605\n",
      "Epoch 251/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3395 - acc: 0.8635 - val_loss: 0.3349 - val_acc: 0.8610\n",
      "Epoch 252/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3390 - acc: 0.8627 - val_loss: 0.3348 - val_acc: 0.8595\n",
      "Epoch 253/300\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3390 - acc: 0.8639 - val_loss: 0.3351 - val_acc: 0.8585\n",
      "Epoch 254/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3391 - acc: 0.8626 - val_loss: 0.3347 - val_acc: 0.8640\n",
      "Epoch 255/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3388 - acc: 0.8627 - val_loss: 0.3337 - val_acc: 0.8615\n",
      "Epoch 256/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3384 - acc: 0.8610 - val_loss: 0.3339 - val_acc: 0.8650\n",
      "Epoch 257/300\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3393 - acc: 0.8626 - val_loss: 0.3338 - val_acc: 0.8615\n",
      "Epoch 258/300\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3387 - acc: 0.8627 - val_loss: 0.3361 - val_acc: 0.8590\n",
      "Epoch 259/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3384 - acc: 0.8621 - val_loss: 0.3343 - val_acc: 0.8640\n",
      "Epoch 260/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3388 - acc: 0.8622 - val_loss: 0.3345 - val_acc: 0.8620\n",
      "Epoch 261/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3393 - acc: 0.8615 - val_loss: 0.3345 - val_acc: 0.8570\n",
      "Epoch 262/300\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3400 - acc: 0.859 - 0s 48us/step - loss: 0.3383 - acc: 0.8609 - val_loss: 0.3348 - val_acc: 0.8665\n",
      "Epoch 263/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3396 - acc: 0.8614 - val_loss: 0.3382 - val_acc: 0.8590\n",
      "Epoch 264/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3390 - acc: 0.8621 - val_loss: 0.3347 - val_acc: 0.8630\n",
      "Epoch 265/300\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3388 - acc: 0.8621 - val_loss: 0.3354 - val_acc: 0.8595\n",
      "Epoch 266/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3389 - acc: 0.8631 - val_loss: 0.3339 - val_acc: 0.8635\n",
      "Epoch 267/300\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3389 - acc: 0.8627 - val_loss: 0.3339 - val_acc: 0.8635\n",
      "Epoch 268/300\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3386 - acc: 0.8619 - val_loss: 0.3345 - val_acc: 0.8655\n",
      "Epoch 269/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3388 - acc: 0.8617 - val_loss: 0.3345 - val_acc: 0.8655\n",
      "Epoch 270/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3393 - acc: 0.8627 - val_loss: 0.3336 - val_acc: 0.8605\n",
      "Epoch 271/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3382 - acc: 0.8632 - val_loss: 0.3394 - val_acc: 0.8575\n",
      "Epoch 272/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3384 - acc: 0.8636 - val_loss: 0.3338 - val_acc: 0.8585\n",
      "Epoch 273/300\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3380 - acc: 0.8612 - val_loss: 0.3390 - val_acc: 0.8580\n",
      "Epoch 274/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3386 - acc: 0.8606 - val_loss: 0.3359 - val_acc: 0.8595\n",
      "Epoch 275/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3386 - acc: 0.8617 - val_loss: 0.3339 - val_acc: 0.8585\n",
      "Epoch 276/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3385 - acc: 0.8635 - val_loss: 0.3350 - val_acc: 0.8610\n",
      "Epoch 277/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3387 - acc: 0.8617 - val_loss: 0.3350 - val_acc: 0.8590\n",
      "Epoch 278/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3388 - acc: 0.8621 - val_loss: 0.3343 - val_acc: 0.8575\n",
      "Epoch 279/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3378 - acc: 0.8620 - val_loss: 0.3404 - val_acc: 0.8550\n",
      "Epoch 280/300\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3387 - acc: 0.8631 - val_loss: 0.3446 - val_acc: 0.8545\n",
      "Epoch 281/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3394 - acc: 0.8627 - val_loss: 0.3333 - val_acc: 0.8610\n",
      "Epoch 282/300\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3384 - acc: 0.8640 - val_loss: 0.3354 - val_acc: 0.8585\n",
      "Epoch 283/300\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.3386 - acc: 0.8621 - val_loss: 0.3383 - val_acc: 0.8600\n",
      "Epoch 284/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3387 - acc: 0.8630 - val_loss: 0.3395 - val_acc: 0.8560\n",
      "Epoch 285/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3382 - acc: 0.8640 - val_loss: 0.3372 - val_acc: 0.8590\n",
      "Epoch 286/300\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3385 - acc: 0.8646 - val_loss: 0.3337 - val_acc: 0.8600\n",
      "Epoch 287/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3389 - acc: 0.8631 - val_loss: 0.3357 - val_acc: 0.8590\n",
      "Epoch 288/300\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.3393 - acc: 0.8621 - val_loss: 0.3345 - val_acc: 0.8585\n",
      "Epoch 289/300\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3388 - acc: 0.8634 - val_loss: 0.3347 - val_acc: 0.8570\n",
      "Epoch 290/300\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3388 - acc: 0.8615 - val_loss: 0.3334 - val_acc: 0.8580\n",
      "Epoch 291/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3380 - acc: 0.8620 - val_loss: 0.3347 - val_acc: 0.8580\n",
      "Epoch 292/300\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3389 - acc: 0.8630 - val_loss: 0.3399 - val_acc: 0.8570\n",
      "Epoch 293/300\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3384 - acc: 0.8625 - val_loss: 0.3390 - val_acc: 0.8595\n",
      "Epoch 294/300\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3387 - acc: 0.8630 - val_loss: 0.3330 - val_acc: 0.8595\n",
      "Epoch 295/300\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3381 - acc: 0.8620 - val_loss: 0.3331 - val_acc: 0.8645\n",
      "Epoch 296/300\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3384 - acc: 0.8621 - val_loss: 0.3326 - val_acc: 0.8640\n",
      "Epoch 297/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3387 - acc: 0.8629 - val_loss: 0.3330 - val_acc: 0.8625\n",
      "Epoch 298/300\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3383 - acc: 0.8629 - val_loss: 0.3399 - val_acc: 0.8575\n",
      "Epoch 299/300\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3386 - acc: 0.8617 - val_loss: 0.3378 - val_acc: 0.8555\n",
      "Epoch 300/300\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3384 - acc: 0.8629 - val_loss: 0.3347 - val_acc: 0.8560\n"
     ]
    }
   ],
   "source": [
    "# Fitting ANN to the Training set\n",
    "h = classifier.fit(X_train, y_train, validation_data = (X_test, y_test), batch_size = 25, epochs = 300, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the loss\n",
    "plt.figure(1)\n",
    "plt.plot(h.history['loss'], label = 'loss')\n",
    "plt.plot(h.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the acc\n",
    "plt.figure(2)\n",
    "plt.plot(h.history['acc'], label = 'acc')\n",
    "plt.plot(h.history['val_acc'], label = 'val_acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "def Classification(clf, X, y):\n",
    "    X_set, y_set = X, y\n",
    "    y_hat = clf.predict(X_set)\n",
    "    y_hat = np.reshape(y_hat, -1)\n",
    "    y_hat[y_hat >= 0.5] = 1\n",
    "    y_hat[y_hat < 0.5] = 0\n",
    "    cm = confusion_matrix(y_set, y_hat)    \n",
    "    TN = cm[0, 0]\n",
    "    FN = cm[1, 0]\n",
    "    TP = cm[1, 1]\n",
    "    FP = cm[0, 1]    \n",
    "    accuracy = (TP + TN)/(TN + FN + TP + FP)\n",
    "    PPV = TP/(TP + FP) # Positive Predictive Value, Precision \n",
    "    TPR = TP/(TP + FN) # Sensitivitive, Recall    \n",
    "    TNR = TN/(TN + FP) # Specificitive\n",
    "    NPV = TN/(TN + FP) # Negative Predictive Value    \n",
    "    F1_score = 2/(1/PPV + 1/TPR)\n",
    "    summary = {'Accuracy': accuracy, \n",
    "               'Positive_Predictive_Value': PPV, \n",
    "               'Negative_Predictive_Value': NPV,            \n",
    "               'Sensitivitive': TPR, \n",
    "               'Specificitive': TNR,            \n",
    "               'F1_score': F1_score, \n",
    "               'CM': cm}\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.863375,\n",
       " 'Positive_Predictive_Value': 0.7549668874172185,\n",
       " 'Negative_Predictive_Value': 0.9593278894472361,\n",
       " 'Sensitivitive': 0.4889705882352941,\n",
       " 'Specificitive': 0.9593278894472361,\n",
       " 'F1_score': 0.5935291930085533,\n",
       " 'CM': array([[6109,  259],\n",
       "        [ 834,  798]], dtype=int64)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification(clf = classifier, X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.856,\n",
       " 'Positive_Predictive_Value': 0.6943521594684385,\n",
       " 'Negative_Predictive_Value': 0.9423197492163009,\n",
       " 'Sensitivitive': 0.5160493827160494,\n",
       " 'Specificitive': 0.9423197492163009,\n",
       " 'F1_score': 0.5920679886685553,\n",
       " 'CM': array([[1503,   92],\n",
       "        [ 196,  209]], dtype=int64)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification(clf = classifier, X = X_test, y = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying k-fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def cv_score(clf, X, y, cv):\n",
    "    accuracies = cross_val_score(estimator = clf, X = X, y = y, scoring = 'f1', cv = cv)\n",
    "    plt.plot(accuracies, '-o')\n",
    "    plt.axhline(accuracies.mean(), color = 'black', ls = '-')\n",
    "    plt.axhline(accuracies.mean() + 2 * accuracies.std(), color = 'black', ls = '--')\n",
    "    plt.axhline(accuracies.mean() - 2 * accuracies.std(), color = 'black', ls = '--')\n",
    "    plt.xlabel('CV')\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.title('Classifier: ' + clf.__class__.__name__)\n",
    "    plt.show()\n",
    "    return [accuracies.mean(), accuracies.std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 25, epochs = 300, verbose = 0)\n",
    "ANN_score = cv_score(clf = classifier, X = X_train, y = y_train, cv = 10)\n",
    "classifier.fit(X_train, y_train)\n",
    "ANN_score.append(classifier.score(X_test, y_test))\n",
    "print('ANN: CV score = %0.3f (+/- %0.3f); Test set accuracy = %0.3f' % (ANN_score[0], 2 * ANN_score[1], ANN_score[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating, Improving and Tuning the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improving the ANN\n",
    "# Dropout Regularization to reduce overfitting if needed\n",
    "# Tuning the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "parameters = {'batch_size': [25, 50], \n",
    "              'epochs': [300], \n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "grid_search = GridSearchCV(estimator = classifier, \n",
    "                           param_grid = parameters, \n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 0)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "results = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
